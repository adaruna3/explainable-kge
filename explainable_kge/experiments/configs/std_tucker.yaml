# Run on GPU (bool)
cuda: True
logging:
  # Log Number (+int)
  log_num: 1
# Session Mode (TRAIN,TEST)
sess_mode: TRAIN
dataset:
  # DataSet name (WN18RR, etc.)
  name: VH+
  # Negative sampling Ratio (+int)
  neg_ratio: 0
  # Negative sampling type (random or type_constrained)
  neg_type: "type_constrained"
  # Whether to add reverse triples to dataset (bool)
  reverse: True
model:
  # Model type (transe, analogy, or tucker)
  name: tucker
  # entity dim size (+int)
  ent_dim: 100
  # relation dim size (+int)
  rel_dim: 25
  # model sepcific args
  arch:
    # input layer dropout rate (float)
    input_dropout: 0.2
    # input layer dropout rate (float)
    hidden_dropout1: 0.3
    # input layer dropout rate (float)
    hidden_dropout2: 0.5
    # ranking difference margin (float)
    margin: 1.0
train:
  # Batch size (+int)
  batch_size: 64
  # Optimization Method to use (adagrad, sgd, etc.)
  opt_method: adam
  # Optimization Parameters list[float]
  opt_params:
    lr: 1e-3
  # Label smooting for training
  label_smooth_rate: 0.1
  # Number of cpu Worker threads batching data (+int)
  num_workers: 16
  # Number of Epochs to train (+int)
  num_epochs: 500
  # Evaluation Frequency (+int)
  valid_freq: 5
  # Early stop Patience (+int)
  patience: 60
  # Cuttoff for triples during Validation (+int)
  valid_cutoff: None
continual:
  # Number of learning Sessions for CL (+int)
  num_sess: 5
  # CL Method (finetune, L2, etc.)
  cl_method: offline
  # CL Regularization strength Scaling (0.0 - 1.0)
  regul_scaling: 0.2
  # Initialization Method (xav, unk,  alc, ...)
  init_method: xav
  # GRUVAE Parameters [ef, ep, ne, bs, op, embedding dim, hidden dim, latent dim, anneal slope, anneal position, anneal max]
  gruvae_args: [10.0, 20.0, 500.0, 1000.0, 0.001, 200, 150, 100, 0.06, 233.0, 0.8]
  # Enable Offline to have access to all triples (bool)
  enable_offline: False
explain:
  xmodel: "logit"
  locality: "global"